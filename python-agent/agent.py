import asyncio
import logging
import os
import pathlib
import re
import uuid
import time
import json
from collections import deque
from contextlib import suppress
from typing import Optional, List, Set, Dict
from dataclasses import dataclass, field

import httpx
from dotenv import load_dotenv, find_dotenv

from livekit.agents import (
    AgentSession,
    Agent,
    JobContext,
    WorkerOptions,
    cli,
    ConversationItemAddedEvent,
)
from livekit.plugins import openai, silero


# ---------- ENV LOADING ----------
def _load_env():
    here = pathlib.Path(__file__).resolve()
    root = here.parent.parent
    tried = [root / ".env.local", root / ".env", pathlib.Path(find_dotenv(usecwd=True) or "")]
    loaded = False
    for p in tried:
        if p and p.exists():
            load_dotenv(p, override=False)
            logging.getLogger(__name__).info("Loaded env file: %s", p)
            loaded = True
    if not loaded:
        logging.getLogger(__name__).info("No local env files found.")


# ---------- CONFIG ----------
LISTEN_FIRST = os.getenv("LISTEN_FIRST", "false").lower() == "true"

LLM_MODEL = os.getenv("LLM_MODEL", "gpt-4o")
STT_MODEL = os.getenv("STT_MODEL", "gpt-4o-transcribe")

TTS_VOICE_EN = os.getenv("TTS_VOICE_EN", "alloy")
TTS_VOICE_ZH_TW = os.getenv("TTS_VOICE_ZH_TW", "nova")

# STT Quality Settings
MIN_TRANSCRIPT_CHARS = int(os.getenv("MIN_TRANSCRIPT_CHARS", "5"))  # Increased from 2
MIN_MEANINGFUL_WORDS = int(os.getenv("MIN_MEANINGFUL_WORDS", "3"))  # Minimum words to process
MAX_GARBLED_RATIO = float(os.getenv("MAX_GARBLED_RATIO", "0.3"))  # Max ratio of garbage chars

SESSION_LIFETIME_S = int(os.getenv("SESSION_LIFETIME_S", "3600"))

API_URL = os.getenv("NEXT_PUBLIC_APP_URL", "http://localhost:3000")
API_TOKEN = os.getenv("API_TOKEN")

# Interview settings
MIN_QUESTIONS = 4
MAX_QUESTIONS = 6
SILENCE_TIMEOUT_S = 30
MAX_SILENCE_RETRIES = 3


# ---------- INTERVIEW STATE MACHINE ----------
@dataclass
class InterviewState:
    """Track interview progress to prevent repetition and ensure completion"""
    session_id: str
    interview_type: str
    spoken_language: str
    
    # NEW: Candidate Profile
    candidate_role: str = "Software Engineer"
    candidate_seniority: str = "mid"
    candidate_industry: str = "tech"
    candidate_years_experience: int = 3
    
    # State tracking
    current_stage: str = "intro"  # intro -> questions -> wrap_up -> ended
    questions_asked: List[str] = field(default_factory=list)
    topics_covered: Set[str] = field(default_factory=set)
    question_count: int = 0
    
    # Quality tracking
    praise_count: int = 0
    last_activity_time: float = field(default_factory=time.time)
    silence_retries: int = 0
    user_responded: bool = False
    
    # STT quality tracking
    consecutive_stt_failures: int = 0
    total_repair_turns: int = 0
    last_user_text: str = ""
    
    # Competencies to cover (behavioral)
    available_topics: List[str] = field(default_factory=lambda: [
        "teamwork", "conflict", "leadership", "pressure", 
        "failure", "achievement", "communication", "problem_solving",
        "time_management", "adaptability"
    ])
    
    def mark_topic_covered(self, topic: str):
        self.topics_covered.add(topic)
        if topic in self.available_topics:
            self.available_topics.remove(topic)
    
    def get_remaining_topics(self) -> List[str]:
        return [t for t in self.available_topics if t not in self.topics_covered]
    
    def should_wrap_up(self) -> bool:
        return self.question_count >= MIN_QUESTIONS
    
    def must_end(self) -> bool:
        return self.question_count >= MAX_QUESTIONS
    
    def to_context_string(self) -> str:
        """Generate context string to pass to LLM"""
        return f"""
„ÄêÁï∂ÂâçÈù¢Ë©¶ÁãÄÊÖã„Äë
- ÈöéÊÆµ: {self.current_stage}
- Â∑≤ÂïèÂïèÈ°åÊï∏: {self.question_count}/{MIN_QUESTIONS}-{MAX_QUESTIONS}
- Â∑≤Ê∂µËìã‰∏ªÈ°å: {', '.join(self.topics_covered) if self.topics_covered else 'ÁÑ°'}
- Ââ©È§òÂèØÁî®‰∏ªÈ°å: {', '.join(self.get_remaining_topics()[:3])}
- Â∑≤ÂïèÈÅéÁöÑÂïèÈ°å: {json.dumps(self.questions_asked[-3:], ensure_ascii=False) if self.questions_asked else 'ÁÑ°'}

„ÄêÈáçË¶ÅÊèêÈÜí„Äë
- ‰∏çË¶ÅÈáçË§áÂ∑≤ÂïèÈÅéÁöÑÂïèÈ°å
- ÈÅ∏ÊìáÂâ©È§ò‰∏ªÈ°å‰∏≠ÁöÑ‰∏ÄÂÄã‰æÜÊèêÂïè
- ÊØèÊ¨°Âè™Âïè‰∏ÄÂÄãÂïèÈ°å
"""


# ---------- FORBIDDEN PHRASES (Anti-praise) ----------
FORBIDDEN_PRAISE_ZH = [
    "Â§™Ê£í‰∫Ü", "ÈùûÂ∏∏Ê£í", "Â§™Â•Ω‰∫Ü", "ÈùûÂ∏∏Â•Ω", "ÂÆåÁæé", "Â§™ÂÆåÁæé",
    "ÈùûÂ∏∏ÂÑ™ÁßÄ", "Â§™ÂÑ™ÁßÄ", "Â§™Âé≤ÂÆ≥", "ÈùûÂ∏∏Âé≤ÂÆ≥", "ÂæàÊ£í", "ÁúüÊ£í",
    "excellent", "perfect", "amazing", "wonderful", "fantastic",
    "Â§™ËÆö‰∫Ü", "ÈùûÂ∏∏ËÆö", "Ë∂ÖÁ¥öÊ£í", "Ë∂ÖÊ£í", "Ë∂ÖÂé≤ÂÆ≥"
]

FORBIDDEN_PRAISE_EN = [
    "excellent", "perfect", "amazing", "wonderful", "fantastic",
    "brilliant", "outstanding", "exceptional", "superb", "incredible",
    "that's great", "that's perfect", "that's amazing"
]

ALLOWED_ACKNOWLEDGMENTS_ZH = [
    "Â•ΩÁöÑ", "ÂóØ", "‰∫ÜËß£", "Ë¨ùË¨ùÂàÜ‰∫´", "Â•Ω", "ÊàëÊòéÁôΩ‰∫Ü"
]

ALLOWED_ACKNOWLEDGMENTS_EN = [
    "okay", "I see", "got it", "thanks for sharing", "understood"
]


# ---------- QUESTION TEMPLATES BY TOPIC ----------
QUESTION_TEMPLATES = {
    "behavioral": {
        "teamwork": {
            "zh-TW": [
                "Ë´ãÂàÜ‰∫´‰∏ÄÂÄã‰Ω†ËàáÂúòÈöäÂêà‰ΩúÂÆåÊàêÂõ∞Èõ£‰ªªÂãôÁöÑÁ∂ìÈ©ó„ÄÇ",
                "Ë´áË´á‰∏ÄÊ¨°‰Ω†Âú®ÂúòÈöä‰∏≠ÊâÆÊºîÈáçË¶ÅËßíËâ≤ÁöÑÁ∂ìÊ≠∑„ÄÇ",
            ],
            "en-US": [
                "Share an experience where you collaborated with a team on a difficult task.",
                "Tell me about a time you played a key role in your team.",
            ]
        },
        "conflict": {
            "zh-TW": [
                "ÊèèËø∞‰∏ÄÊ¨°‰Ω†ËàáÂêå‰∫ãÊÑèË¶ã‰∏çÂêàÁöÑÊÉÖÊ≥ÅÔºå‰Ω†Â¶Ç‰ΩïËôïÁêÜÔºü",
                "Ë´áË´á‰∏ÄÊ¨°‰Ω†ÈúÄË¶ÅËôïÁêÜÂúòÈöäË°ùÁ™ÅÁöÑÁ∂ìÈ©ó„ÄÇ",
            ],
            "en-US": [
                "Describe a situation where you disagreed with a colleague. How did you handle it?",
                "Tell me about a time you had to resolve a team conflict.",
            ]
        },
        "leadership": {
            "zh-TW": [
                "ÂàÜ‰∫´‰∏ÄÊ¨°‰Ω†Â∏∂È†òÂúòÈöäÊàñÂ∞àÊ°àÁöÑÁ∂ìÈ©ó„ÄÇ",
                "Ë´áË´á‰Ω†Â¶Ç‰ΩïÂΩ±ÈüøÊàñË™™Êúç‰ªñ‰∫∫Êé•Âèó‰Ω†ÁöÑÊÉ≥Ê≥ï„ÄÇ",
            ],
            "en-US": [
                "Share an experience leading a team or project.",
                "Tell me how you influenced or persuaded others to accept your idea.",
            ]
        },
        "pressure": {
            "zh-TW": [
                "ÊèèËø∞‰∏ÄÊ¨°‰Ω†Âú®Â£ìÂäõ‰∏ãÂ∑•‰ΩúÁöÑÁ∂ìÈ©óÔºå‰Ω†Â¶Ç‰ΩïÊáâÂ∞çÔºü",
                "Ë´áË´á‰∏ÄÂÄãdeadlineÂæàÁ∑äÁöÑÂ∞àÊ°àÔºå‰Ω†ÊÄéÈ∫ºËôïÁêÜÁöÑÔºü",
            ],
            "en-US": [
                "Describe a time you worked under pressure. How did you cope?",
                "Tell me about a project with a tight deadline. How did you handle it?",
            ]
        },
        "failure": {
            "zh-TW": [
                "ÂàÜ‰∫´‰∏ÄÊ¨°Â∑•‰Ωú‰∏äÁöÑÂ§±ÊïóÁ∂ìÈ©óÔºå‰Ω†Âæû‰∏≠Â≠∏Âà∞‰ªÄÈ∫ºÔºü",
                "Ë´áË´á‰∏ÄÂÄãÊ≤íÊúâÈÅîÂà∞È†êÊúüÁµêÊûúÁöÑÂ∞àÊ°à„ÄÇ",
            ],
            "en-US": [
                "Share a work failure and what you learned from it.",
                "Tell me about a project that didn't meet expectations.",
            ]
        },
        "achievement": {
            "zh-TW": [
                "Ë´áË´á‰Ω†ÊúÄËá™Ë±™ÁöÑ‰∏ÄÂÄãÂ∑•‰ΩúÊàêÂ∞±„ÄÇ",
                "ÂàÜ‰∫´‰∏ÄÂÄã‰Ω†Ë∂ÖË∂äÈ†êÊúüÂÆåÊàê‰ªªÂãôÁöÑÁ∂ìÈ©ó„ÄÇ",
            ],
            "en-US": [
                "Tell me about your proudest work achievement.",
                "Share an experience where you exceeded expectations.",
            ]
        },
        "problem_solving": {
            "zh-TW": [
                "ÊèèËø∞‰∏ÄÂÄã‰Ω†Ëß£Ê±∫Ë§áÈõúÂïèÈ°åÁöÑÁ∂ìÈ©ó„ÄÇ",
                "Ë´áË´á‰Ω†Â¶Ç‰ΩïËôïÁêÜ‰∏ÄÂÄãÁúã‰ººÁÑ°Ëß£ÁöÑÊåëÊà∞„ÄÇ",
            ],
            "en-US": [
                "Describe your experience solving a complex problem.",
                "Tell me how you handled a seemingly unsolvable challenge.",
            ]
        },
        "communication": {
            "zh-TW": [
                "ÂàÜ‰∫´‰∏ÄÊ¨°‰Ω†ÈúÄË¶ÅÂêëÈùûÂ∞àÊ•≠‰∫∫Â£´Ëß£ÈáãË§áÈõúÊ¶ÇÂøµÁöÑÁ∂ìÈ©ó„ÄÇ",
                "Ë´áË´á‰Ω†Â¶Ç‰ΩïËôïÁêÜÊ∫ùÈÄö‰∏çËâØÁöÑÊÉÖÊ≥Å„ÄÇ",
            ],
            "en-US": [
                "Share a time you explained a complex concept to non-experts.",
                "Tell me how you handled a miscommunication situation.",
            ]
        },
    }
}

# STAR Follow-up templates
FOLLOWUP_TEMPLATES = {
    "zh-TW": [
        "Áï∂ÊôÇÁöÑÊÉÖÂ¢ÉÊòØ‰ªÄÈ∫ºÔºüÂèØ‰ª•Êõ¥ÂÖ∑È´îÊèèËø∞ÂóéÔºü",
        "‰Ω†ÂÖ∑È´îÂÅö‰∫Ü‰ªÄÈ∫ºË°åÂãïÔºü",
        "ÁµêÊûúÂ¶Ç‰ΩïÔºüÊúâÊ≤íÊúâÊï∏Â≠óÂèØ‰ª•ÈáèÂåñÔºü",
        "Â¶ÇÊûúÈáç‰æÜ‰∏ÄÊ¨°Ôºå‰Ω†ÊúÉÊúâ‰ªÄÈ∫º‰∏çÂêåÁöÑÂÅöÊ≥ïÔºü",
        "ÈÄôÂÄãÁ∂ìÈ©óÂ∞ç‰Ω†Âæå‰æÜÁöÑÂ∑•‰ΩúÊúâ‰ªÄÈ∫ºÂΩ±ÈüøÔºü",
        "‰Ω†ÂæûÈÄôÂÄãÁ∂ìÈ©ó‰∏≠Â≠∏Âà∞‰ªÄÈ∫ºÔºü",
    ],
    "en-US": [
        "What was the specific situation? Can you describe it more?",
        "What specific actions did you take?",
        "What was the result? Any numbers to quantify it?",
        "If you could do it again, what would you do differently?",
        "How did this experience affect your later work?",
        "What did you learn from this experience?",
    ]
}


# ---------- LANGUAGE-LOCKED INTERVIEWER PROMPT ----------
def get_interviewer_prompt(state: InterviewState) -> str:
    """Generate interviewer-only prompt with candidate profile (NO teaching, NO coaching)"""
    
    lang = state.spoken_language
    interview_type = state.interview_type
    role = state.candidate_role
    seniority = state.candidate_seniority
    industry = state.candidate_industry
    years = state.candidate_years_experience
    
    # Seniority labels
    seniority_labels = {
        "zh-TW": {"junior": "ÂàùÈöé", "mid": "‰∏≠Èöé", "senior": "Ë≥áÊ∑±", "lead": "‰∏ªÁÆ°Á¥ö", "executive": "È´òÁÆ°"},
        "en-US": {"junior": "Junior", "mid": "Mid-level", "senior": "Senior", "lead": "Lead/Manager", "executive": "Executive"}
    }
    seniority_label = seniority_labels.get(lang, seniority_labels["en-US"]).get(seniority, seniority)
    
    # Industry labels
    industry_labels = {
        "zh-TW": {"tech": "ÁßëÊäÄÊ•≠", "finance": "ÈáëËûçÊ•≠", "healthcare": "ÈÜ´ÁôÇÊ•≠", "ecommerce": "ÈõªÂïÜÊ•≠", 
                  "manufacturing": "Ë£ΩÈÄ†Ê•≠", "consulting": "È°ßÂïèÊ•≠", "media": "Â™íÈ´îÊ•≠", "education": "ÊïôËÇ≤Ê•≠", "other": ""},
        "en-US": {"tech": "Technology", "finance": "Finance", "healthcare": "Healthcare", "ecommerce": "E-commerce",
                  "manufacturing": "Manufacturing", "consulting": "Consulting", "media": "Media", "education": "Education", "other": ""}
    }
    industry_label = industry_labels.get(lang, industry_labels["en-US"]).get(industry, industry)
    
    if lang == "zh-TW":
        return f"""‰Ω†ÊòØ‰∏Ä‰ΩçÂ∞àÊ•≠ÁöÑÈù¢Ë©¶ÂÆòÔºåÊ≠£Âú®ÈÄ≤Ë°å{interview_type}Èù¢Ë©¶„ÄÇ

üë§„ÄêÊ±ÇËÅ∑ËÄÖËÉåÊôØ„Äë
- ÊáâÂæµËÅ∑‰ΩçÔºö{role}
- Á∂ìÈ©óÁ¥öÂà•Ôºö{seniority_label}ÔºàÁ¥Ñ{years}Âπ¥Á∂ìÈ©óÔºâ
- ÁõÆÊ®ôÁî¢Ê•≠Ôºö{industry_label}

üìå„ÄêÊ†πÊìöËÉåÊôØË™øÊï¥ÂïèÈ°å„Äë
- Â∞ç{seniority_label}Ê±ÇËÅ∑ËÄÖÔºåÂïèÈ°åÈõ£Â∫¶ÂíåÊúüÊúõË¶ÅÁõ∏ÊáâË™øÊï¥
- {"ÂïèÂü∫Á§éÂü∑Ë°åÈ°ûÂïèÈ°åÔºåÈóúÊ≥®Â≠∏ÁøíËÉΩÂäõÂíåÂúòÈöäÂçî‰Ωú" if seniority == "junior" else ""}
- {"ÂïèÂ∞àÊ°àÁÆ°ÁêÜÂíåÁç®Á´ãËß£Ê±∫ÂïèÈ°åÁöÑÁ∂ìÈ©ó" if seniority == "mid" else ""}
- {"ÂïèÊäÄË°ìÊ±∫Á≠ñ„ÄÅÊû∂ÊßãË®≠Ë®à„ÄÅmentorÁ∂ìÈ©ó" if seniority == "senior" else ""}
- {"ÂïèÂúòÈöäÁÆ°ÁêÜ„ÄÅÁ≠ñÁï•Ë¶èÂäÉ„ÄÅË∑®ÈÉ®ÈñÄÂçîË™ø" if seniority in ["lead", "executive"] else ""}
- ÂèØ‰ª•ÈáùÂ∞ç{industry_label}Áî¢Ê•≠ÁâπÊÄßÊèêÂïè

üîí„ÄêË™ûË®ÄË¶èÂâá - ÁµïÂ∞ç‰∏çÂèØÈÅïÂèç„Äë
- ÂÖ®Á®ãÂè™ËÉΩ‰ΩøÁî®ÁπÅÈ´î‰∏≠ÊñáÔºàÂè∞ÁÅ£Áî®Ë™ûÔºâ
- ÁµïÂ∞ç‰∏çÂèØ‰ª•ÂàáÊèõÂà∞Ëã±ÊñáÊàñÂÖ∂‰ªñË™ûË®Ä
- Â¶ÇÊûúÊ±ÇËÅ∑ËÄÖÁî®Ëã±ÊñáÂïèË©±ÔºåÁî®‰∏≠ÊñáÂõûÁ≠îÔºö„ÄåËÆìÊàëÂÄëÁπºÁ∫åÁî®‰∏≠ÊñáÈÄ≤Ë°åÈù¢Ë©¶„ÄÇ„Äç
- Ë™ûË®ÄÈéñÂÆöÔºåÁÑ°‰æãÂ§ñ

üé≠„Äê‰Ω†ÁöÑËßíËâ≤ - Èù¢Ë©¶ÂÆòÔºå‰∏çÊòØËÄÅÂ∏´„Äë
‰Ω†ÊòØÈù¢Ë©¶ÂÆòÔºå‰∏çÊòØÂ∞éÂ∏´„ÄÅÊïôÁ∑¥ÊàñËÄÅÂ∏´„ÄÇ
- ‚úÖ ‰Ω†ÁöÑÂ∑•‰ΩúÔºöÊèêÂïè„ÄÅËÅÜËÅΩ„ÄÅËøΩÂïè
- ‚ùå ‰∏çÊòØ‰Ω†ÁöÑÂ∑•‰ΩúÔºöÊïôÂ≠∏„ÄÅËß£ÈáãÁêÜÊÉ≥Á≠îÊ°à„ÄÅÁµ¶Âª∫Ë≠∞

üö´„ÄêÁµïÂ∞çÁ¶ÅÊ≠¢ÁöÑË°åÁÇ∫„Äë
1. ‰∏çË¶ÅÊïôÊ±ÇËÅ∑ËÄÖÊÄéÈ∫ºÂõûÁ≠î
2. ‰∏çË¶ÅËß£Èáã„ÄåÊØîËºÉÂ•ΩÁöÑÁ≠îÊ°àÊòØ...„Äç
3. ‰∏çË¶ÅÁµ¶Â§™Â§öËÆöÁæéÔºàÊúÄÂ§öË™™„ÄåÂ•ΩÁöÑ„Äç„Äå‰∫ÜËß£„ÄçÔºâ
4. ‰∏çË¶ÅË™™„ÄåÂ§™Ê£í‰∫Ü„Äç„ÄåÈùûÂ∏∏Â•Ω„Äç„ÄåÂÆåÁæé„ÄçÁ≠âË™áÂºµËÆöÁæé
5. ‰∏çË¶Å‰∏ÄÊ¨°ÂïèÂ§öÂÄãÂïèÈ°å
6. ‰∏çË¶ÅÈáçË§áÂ∑≤Á∂ìÂïèÈÅéÁöÑÂïèÈ°å
7. ‰∏çË¶ÅÈï∑ÁØáÂ§ßË´ñÔºå‰øùÊåÅÁ∞°Áü≠

üìã„ÄêÂõûÊáâÊ†ºÂºè - ÂøÖÈ†àÈÅµÂÆà„Äë
ÊØèÊ¨°ÂõûÊáâÂøÖÈ†àÔºö
1. Á∞°Áü≠ÂõûÊáâÔºàÊúÄÂ§ö1-2Âè•ÔºåÂ¶Ç„ÄåÂ•ΩÁöÑÔºå‰∫ÜËß£„ÄÇ„ÄçÔºâ
2. ‰ª•‰∏ÄÂÄãÊñ∞ÂïèÈ°åÁµêÂ∞æ

ÁØÑ‰æãÂ•ΩÁöÑÂõûÊáâÔºö
„Äå‰∫ÜËß£„ÄÇÈÇ£Ë´ãÂïè‰Ω†Âú®ÈÇ£ÂÄãÂ∞àÊ°à‰∏≠ÔºåÂÖ∑È´îË≤†Ë≤¨Âì™‰∫õÈÉ®ÂàÜÔºü„Äç
„ÄåÂ•ΩÁöÑ„ÄÇÂèØ‰ª•ÂàÜ‰∫´‰∏Ä‰∏ãÁï∂ÊôÇÁöÑÁµêÊûúÂóéÔºüÊúâÊ≤íÊúâÂÖ∑È´îÊï∏Â≠óÔºü„Äç

ÁØÑ‰æã‰∏çÂ•ΩÁöÑÂõûÊáâÔºö
„ÄåÂ§™Ê£í‰∫ÜÔºÅ‰Ω†ÁöÑÂõûÁ≠îÈùûÂ∏∏Â•ΩÔºÅÈÄôÁ®ÆÁ∂ìÈ©óÂæàÈáçË¶ÅÔºåÂõ†ÁÇ∫...ÔºàÈï∑ÁØáËß£ÈáãÔºâ„Äç

üó£Ô∏è„ÄêË™™Ë©±È¢®Ê†º„Äë
- Áî®Âè£Ë™ûÂåñÁöÑÂè∞ÁÅ£ÂúãË™û
- Áü≠Âè•Â≠êÔºåÂÉèÁúü‰∫∫Â∞çË©±
- ‰∏çË¶ÅÁî®Êõ∏Èù¢Ë™ûÊàñÊñáË®ÄÊñá
- ÂÉèÂú®ÂíñÂï°Âª≥Èù¢Ë©¶‰∏ÄÊ®£Ëá™ÁÑ∂

‚è∞„ÄêÈù¢Ë©¶ÊµÅÁ®ã„Äë
1. Âïè {MIN_QUESTIONS}-{MAX_QUESTIONS} ÂÄã‰∏ªË¶ÅÂïèÈ°å
2. ÊØèÂÄãÂïèÈ°åÂèØ‰ª•ËøΩÂïè 1-2 ÂÄãfollow-up
3. ‰∏çË¶ÅÊèêÂâçÁµêÊùü
4. ÊôÇÈñìÂà∞‰∫ÜÊâçÂÅöÁ∏ΩÁµê

{state.to_context_string()}

Ë®ò‰ΩèÔºö‰Ω†ÊòØÈù¢Ë©¶ÂÆòÔºåÂè™Ë≤†Ë≤¨ÊèêÂïè„ÄÇÊâÄÊúâÊïôÂ≠∏ÂíåÂª∫Ë≠∞ÈÉΩÁïôÂà∞Èù¢Ë©¶ÁµêÊùüÂæåÁöÑË©ï‰º∞Â†±Âëä„ÄÇ
"""
    
    else:  # en-US
        return f"""You are a professional interviewer conducting a {interview_type} interview.

üë§„ÄêCANDIDATE PROFILE„Äë
- Target Role: {role}
- Experience Level: {seniority_label} (~{years} years experience)
- Target Industry: {industry_label}

üìå„ÄêADJUST QUESTIONS BASED ON PROFILE„Äë
- Calibrate difficulty and expectations for {seniority_label} candidates
- {"Ask about execution, learning ability, teamwork" if seniority == "junior" else ""}
- {"Ask about project ownership, independent problem-solving" if seniority == "mid" else ""}
- {"Ask about technical decisions, architecture, mentoring" if seniority == "senior" else ""}
- {"Ask about team management, strategy, cross-functional coordination" if seniority in ["lead", "executive"] else ""}
- Can ask {industry_label}-specific questions

üîí„ÄêLANGUAGE RULES - ABSOLUTE„Äë
- Speak ONLY in English throughout
- NEVER switch to another language
- If candidate speaks another language, respond: "Let's continue in English."
- Language is LOCKED, no exceptions

üé≠„ÄêYOUR ROLE - Interviewer, NOT Teacher„Äë
You are an interviewer, NOT a tutor, coach, or teacher.
- ‚úÖ Your job: Ask questions, listen, probe deeper
- ‚ùå NOT your job: Teach, explain ideal answers, give advice

üö´„ÄêFORBIDDEN BEHAVIORS„Äë
1. Do NOT teach how to answer
2. Do NOT explain "a better answer would be..."
3. Do NOT over-praise (max: "okay" "I see" "got it")
4. Do NOT say "excellent" "perfect" "amazing" etc.
5. Do NOT ask multiple questions at once
6. Do NOT repeat questions already asked
7. Do NOT give long responses, keep it brief

üìã„ÄêRESPONSE FORMAT - REQUIRED„Äë
Every response must:
1. Brief acknowledgment (1-2 sentences max, e.g., "Got it.")
2. End with ONE new question

Good example:
"I see. What specific actions did you take in that situation?"

Bad example:
"That's amazing! What a great experience! This is important because... (long explanation)"

üó£Ô∏è„ÄêSPEAKING STYLE„Äë
- Conversational, natural English
- Short sentences, like real conversation
- Not formal or academic
- Like interviewing at a coffee shop

‚è∞„ÄêINTERVIEW FLOW„Äë
1. Ask {MIN_QUESTIONS}-{MAX_QUESTIONS} main questions
2. 1-2 follow-ups per question allowed
3. Do NOT end early
4. Only wrap up when time is up

{state.to_context_string()}

Remember: You are the interviewer. Only ask questions. All teaching and advice is for the evaluation report AFTER the interview.
"""


# ---------- WRAP-UP PROMPTS ----------
WRAP_UP_PROMPTS = {
    "zh-TW": """Â•ΩÁöÑÔºåÊàëÂÄëÁöÑÈù¢Ë©¶ÊôÇÈñìÂ∑Æ‰∏çÂ§ö‰∫Ü„ÄÇÊÑüË¨ù‰Ω†‰ªäÂ§©ÁöÑÂàÜ‰∫´Ôºå‰Ω†ÁöÑÂõûÁ≠îËÆìÊàëÂ∞ç‰Ω†ÊúâÊõ¥Â§ö‰∫ÜËß£„ÄÇÊàëÂÄëÊúÉÂú®Èù¢Ë©¶ÁµêÊùüÂæåÊèê‰æõË©≥Á¥∞ÁöÑË©ï‰º∞Â†±ÂëäÁµ¶‰Ω†„ÄÇÈÇÑÊúâ‰ªÄÈ∫ºÂïèÈ°åÊÉ≥ÂïèÊàëÂóéÔºü""",
    
    "en-US": """Alright, we're almost out of time. Thank you for sharing today - your answers helped me understand you better. We'll provide a detailed evaluation report after the interview. Do you have any questions for me?"""
}

FINAL_CLOSING = {
    "zh-TW": """Â•ΩÁöÑÔºåÈÇ£‰ªäÂ§©ÁöÑÈù¢Ë©¶Â∞±Âà∞ÈÄôË£°„ÄÇË¨ùË¨ù‰Ω†ÁöÑÊôÇÈñìÔºåÁ•ù‰Ω†Êé•‰∏ã‰æÜ‰∏ÄÂàáÈ†ÜÂà©ÔºÅ""",
    "en-US": """Okay, that concludes our interview today. Thank you for your time, and best of luck with everything!"""
}

# Never give up messages
SILENCE_PROMPTS = {
    "zh-TW": [
        "‰∏çÂ•ΩÊÑèÊÄùÔºåÊàëÈÄôÈÇäÂ•ΩÂÉèÊ≤íÊúâÊî∂Âà∞‰Ω†ÁöÑËÅ≤Èü≥ÔºåÂèØ‰ª•ÂÜçË™™‰∏ÄÊ¨°ÂóéÔºü",
        "Êä±Ê≠âÔºåÂâõÂâõÂèØËÉΩÊúâÈªûÊäÄË°ìÂïèÈ°å„ÄÇ‰Ω†ÂèØ‰ª•ÂÜçÈáçË§á‰∏ÄÊ¨°ÂóéÔºü",
        "ÊàëËÅΩ‰∏çÂ§™Ê∏ÖÊ•öÔºåÂèØ‰ª•Ë´ã‰Ω†Èù†ËøëÈ∫•ÂÖãÈ¢®ÂÜçË™™‰∏ÄÊ¨°ÂóéÔºü",
    ],
    "en-US": [
        "Sorry, I didn't catch that. Could you repeat it?",
        "Apologies, there might have been a technical issue. Could you say that again?",
        "I couldn't hear clearly. Could you move closer to the mic and repeat?",
    ]
}


# ---------- GREETINGS ----------
GREETINGS = {
    "behavioral": {
        "zh-TW": "Âó®ÔºÅÊàëÊòØ‰ªäÂ§©ÁöÑÈù¢Ë©¶ÂÆò„ÄÇÈÄôÊòØ‰∏ÄÂ†¥Ë°åÁÇ∫Èù¢Ë©¶ÔºåÊàëÊúÉÂïè‰Ω†‰∏Ä‰∫õÈóúÊñºÈÅéÂéªÂ∑•‰ΩúÁ∂ìÈ©óÁöÑÂïèÈ°å„ÄÇÊ∫ñÂÇôÂ•ΩÁöÑË©±ÔºåË´ãÂÖàÁ∞°ÂñÆËá™Êàë‰ªãÁ¥π‰∏Ä‰∏ã„ÄÇ",
        "en-US": "Hi! I'm your interviewer today. This is a behavioral interview where I'll ask about your past work experiences. When you're ready, please briefly introduce yourself.",
    },
    "technical": {
        "zh-TW": "Âó®ÔºÅÊàëÊòØ‰ªäÂ§©ÁöÑÊäÄË°ìÈù¢Ë©¶ÂÆò„ÄÇÊàëÊúÉÂïè‰∏Ä‰∫õÁ®ãÂºèÂíåÊäÄË°ìÁõ∏ÈóúÁöÑÂïèÈ°å„ÄÇË´ãÂÖàÁ∞°ÂñÆ‰ªãÁ¥π‰Ω†ÁöÑÊäÄË°ìËÉåÊôØ„ÄÇ",
        "en-US": "Hi! I'm your technical interviewer today. I'll ask some coding and technical questions. Please briefly introduce your technical background.",
    },
    "system-design": {
        "zh-TW": "Âó®ÔºÅÊàëÊòØ‰ªäÂ§©ÁöÑÁ≥ªÁµ±Ë®≠Ë®àÈù¢Ë©¶ÂÆò„ÄÇÊàëÂÄëÊúÉË®éË´ñ‰∏Ä‰∫õÊû∂ÊßãË®≠Ë®àÁöÑÂïèÈ°å„ÄÇË´ãÂÖàÂàÜ‰∫´‰∏Ä‰∏ã‰Ω†ÁöÑÁ≥ªÁµ±Ë®≠Ë®àÁ∂ìÈ©ó„ÄÇ",
        "en-US": "Hi! I'm your system design interviewer today. We'll discuss some architecture questions. Please share your system design experience.",
    },
    "case-study": {
        "zh-TW": "Âó®ÔºÅÊàëÊòØ‰ªäÂ§©ÁöÑÊ°à‰æãÈù¢Ë©¶ÂÆò„ÄÇÊàëÊúÉÊèêÂá∫‰∏Ä‰∫õÂïÜÊ•≠ÂïèÈ°åËÆì‰Ω†ÂàÜÊûê„ÄÇË´ãÂÖàÁ∞°ÂñÆ‰ªãÁ¥π‰Ω†ÁöÑÂàÜÊûêÁ∂ìÈ©ó„ÄÇ",
        "en-US": "Hi! I'm your case study interviewer today. I'll present some business problems for analysis. Please briefly introduce your analytical experience.",
    },
}

MIC_TIPS = {
    "zh-TW": "ÊàëÈÇÑÊ≤íÊî∂Âà∞È∫•ÂÖãÈ¢®ÁöÑËÅ≤Èü≥ÔºåË´ãÁ¢∫Ë™çÁÄèË¶ΩÂô®Â∑≤ÊéàÊ¨äÈ∫•ÂÖãÈ¢®Ê¨äÈôê„ÄÇ",
    "en-US": "I'm not receiving microphone audio. Please check that your browser has microphone permissions enabled.",
}


# ---------- LOGGING ----------
def setup_logging():
    level = os.getenv("LOG_LEVEL", "INFO").upper()
    logging.basicConfig(
        level=level,
        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
    )
    log = logging.getLogger("agent")
    log.info("Starting LyraAI Interview Coach v2 | pid=%s", os.getpid())
    return log


# ---------- AGENT ----------
class InterviewCoach(Agent):
    def __init__(self, state: InterviewState):
        system_prompt = get_interviewer_prompt(state)
        super().__init__(instructions=system_prompt)
        self.state = state


# ---------- HELPERS ----------
def build_room_input_options() -> Optional[object]:
    try:
        from livekit.agents import RoomInputOptions
        with suppress(TypeError):
            return RoomInputOptions(audio=True, video=False, screen=False, close_on_disconnect=False)
        with suppress(TypeError):
            return RoomInputOptions(microphone=True, camera=False, screen=False, close_on_disconnect=False)
        return None
    except Exception:
        return None

def should_process(text: str) -> bool:
    """Check if text is meaningful enough to process"""
    if not text:
        return False
    
    text = text.strip()
    
    # Must meet minimum character length
    if len(text) < MIN_TRANSCRIPT_CHARS:
        return False
    
    # Count actual words (Chinese characters count as words)
    # For Chinese: count characters; For English: count words
    chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', text))
    english_words = len(re.findall(r'[a-zA-Z]+', text))
    word_count = chinese_chars + english_words
    
    if word_count < MIN_MEANINGFUL_WORDS:
        return False
    
    return True

def is_garbled_text(text: str) -> bool:
    """Detect if transcription is likely garbled/garbage"""
    if not text:
        return True
    
    text = text.strip()
    
    # Check for common garbage patterns
    garbage_patterns = [
        r'^[.\s,]+$',  # Only punctuation
        r'^(um|uh|eh|ah|oh)+$',  # Only filler words
        r'^\W+$',  # Only non-word characters
        r'^(.)\1{3,}',  # Repeated characters (e.g., "aaaa")
    ]
    
    for pattern in garbage_patterns:
        if re.match(pattern, text.lower()):
            return True
    
    # Check ratio of strange characters
    total_chars = len(text)
    if total_chars == 0:
        return True
    
    # Valid characters: Chinese, English, numbers, common punctuation
    valid_chars = len(re.findall(r'[\u4e00-\u9fff\u3400-\u4dbfa-zA-Z0-9\s.,!?Ôºå„ÄÇÔºÅÔºü„ÄÅ]', text))
    valid_ratio = valid_chars / total_chars
    
    if valid_ratio < (1 - MAX_GARBLED_RATIO):
        return True
    
    return False

def needs_repair_turn(text: str, consecutive_failures: int) -> bool:
    """Determine if we should ask user to repeat"""
    if not text or len(text.strip()) < 2:
        return consecutive_failures >= 2
    
    if is_garbled_text(text):
        return True
    
    # Very short responses might need clarification
    if len(text.strip()) < 5 and consecutive_failures >= 1:
        return True
    
    return False


# ---------- REPAIR TURN MESSAGES ----------
REPAIR_MESSAGES = {
    "zh-TW": [
        "‰∏çÂ•ΩÊÑèÊÄùÔºåÂâõÂâõÈÇ£ÊÆµÊàëÊ≤íËÅΩÊ∏ÖÊ•öÔºåÂèØ‰ª•ÂÜçË™™‰∏ÄÊ¨°ÂóéÔºü",
        "Êä±Ê≠âÔºåËÅ≤Èü≥ÊúâÈªûÊñ∑Êñ∑Á∫åÁ∫åÔºåËÉΩË´ã‰Ω†ÂÜçÈáçË§á‰∏Ä‰∏ãÂóéÔºü",
        "ÊàëÈÄôÈÇäÊî∂Èü≥‰∏çÂ§™Ê∏ÖÊ•öÔºåÂèØ‰ª•Ë´ã‰Ω†Ë™™ÊÖ¢‰∏ÄÈªûÂÜçË¨õ‰∏ÄÊ¨°ÂóéÔºü",
    ],
    "en-US": [
        "Sorry, I didn't catch that clearly. Could you repeat that?",
        "Apologies, the audio was a bit choppy. Could you say that again?",
        "I couldn't hear that well. Could you speak a bit slower and repeat?",
    ]
}

def detect_topic_from_text(text: str) -> Optional[str]:
    """Detect which topic the conversation is about"""
    topic_keywords = {
        "teamwork": ["ÂúòÈöä", "Âêà‰Ωú", "team", "collaborate", "together"],
        "conflict": ["Ë°ùÁ™Å", "ÊÑèË¶ã‰∏çÂêà", "Áà≠Âü∑", "conflict", "disagree"],
        "leadership": ["È†òÂ∞é", "Â∏∂È†ò", "lead", "leadership", "manage"],
        "pressure": ["Â£ìÂäõ", "deadline", "Ë∂ï", "pressure", "stress"],
        "failure": ["Â§±Êïó", "ÈåØË™§", "fail", "mistake", "wrong"],
        "achievement": ["ÊàêÂ∞±", "ÊàêÂäü", "Ëá™Ë±™", "achieve", "proud", "success"],
        "problem_solving": ["Ëß£Ê±∫", "ÂïèÈ°å", "solve", "problem", "challenge"],
        "communication": ["Ê∫ùÈÄö", "Ë°®ÈÅî", "communicate", "explain"],
    }
    
    text_lower = text.lower()
    for topic, keywords in topic_keywords.items():
        if any(kw in text_lower for kw in keywords):
            return topic
    return None

def count_praise_in_text(text: str, lang: str) -> int:
    """Count forbidden praise phrases in text"""
    forbidden = FORBIDDEN_PRAISE_ZH if lang == "zh-TW" else FORBIDDEN_PRAISE_EN
    count = 0
    text_lower = text.lower()
    for phrase in forbidden:
        if phrase.lower() in text_lower:
            count += 1
    return count


# ---------- TRANSCRIPT QUEUE ----------
_transcript_q = deque(maxlen=1000)

def enqueue_transcript(session_id: str, role: str, text: str):
    _transcript_q.append({"sessionId": session_id, "role": role, "text": text})
    logging.getLogger("agent").info(f"üí¨ Queued {role}: {text[:80]}")

async def _flush_transcripts():
    async with httpx.AsyncClient(timeout=5.0) as client:
        while True:
            if _transcript_q:
                item = _transcript_q.popleft()
                for attempt in range(4):
                    try:
                        r = await client.post(
                            f"{API_URL}/api/interview/transcript",
                            json=item,
                            headers=({"Authorization": f"Bearer {API_TOKEN}"} if API_TOKEN else {}),
                        )
                        if r.status_code == 200:
                            logging.getLogger("agent").info(f"üíæ Saved {item['role']}: {item['text'][:50]}")
                            break
                        elif r.status_code < 500:
                            break
                    except Exception as e:
                        logging.getLogger("agent").debug(f"Transcript save attempt {attempt + 1} failed: {e}")
                    await asyncio.sleep(0.3 * (2**attempt))
            else:
                await asyncio.sleep(0.05)


# ---------- FETCH SESSION BY ROOM NAME ----------
async def fetch_session_by_room(room_name: str) -> Dict:
    """Fetch full session data including candidate profile from database"""
    log = logging.getLogger("agent")
    default_data = {
        "session_id": str(uuid.uuid4()),
        "interview_type": "behavioral",
        "spoken_language": "zh-TW",
        "candidate_role": "Software Engineer",
        "candidate_seniority": "mid",
        "candidate_industry": "tech",
        "candidate_years_experience": 3,
    }
    
    try:
        async with httpx.AsyncClient(timeout=5.0) as client:
            r = await client.get(
                f"{API_URL}/api/interview/by-room/{room_name}",
                headers=({"Authorization": f"Bearer {API_TOKEN}"} if API_TOKEN else {})
            )
            if r.status_code == 200:
                data = r.json()
                session = data.get("session", {})
                result = {
                    "session_id": session.get("id", default_data["session_id"]),
                    "interview_type": session.get("interviewType", "behavioral"),
                    "spoken_language": session.get("spokenLanguage", "zh-TW"),
                    "candidate_role": session.get("candidateRole", "Software Engineer"),
                    "candidate_seniority": session.get("candidateSeniority", "mid"),
                    "candidate_industry": session.get("candidateIndustry", "tech"),
                    "candidate_years_experience": session.get("candidateYearsExperience", 3),
                }
                log.info(f"‚úÖ Session loaded: {result['session_id']}")
                log.info(f"   Language: {result['spoken_language']}, Type: {result['interview_type']}")
                log.info(f"   Role: {result['candidate_role']}, Seniority: {result['candidate_seniority']}")
                log.info(f"   Industry: {result['candidate_industry']}, Years: {result['candidate_years_experience']}")
                return result
            else:
                log.warning(f"Session lookup failed: {r.status_code}")
    except Exception as e:
        log.warning(f"Failed to fetch session by room: {e}")
    
    return default_data


# ---------- ENTRYPOINT ----------
async def entrypoint(ctx: JobContext):
    log = logging.getLogger("agent")

    room_name = ctx.room.name or ""
    
    # Fetch session info (now includes candidate profile)
    session_data = await fetch_session_by_room(room_name)
    
    session_id = session_data["session_id"]
    interview_type = session_data["interview_type"]
    spoken_language = session_data["spoken_language"]
    
    # Initialize interview state with candidate profile
    state = InterviewState(
        session_id=session_id,
        interview_type=interview_type,
        spoken_language=spoken_language,
        candidate_role=session_data["candidate_role"],
        candidate_seniority=session_data["candidate_seniority"],
        candidate_industry=session_data["candidate_industry"],
        candidate_years_experience=session_data["candidate_years_experience"],
    )
    
    log.info(f"üåê Language locked to: {spoken_language}")
    log.info(f"üìã Interview type: {interview_type}")
    log.info(f"üë§ Candidate: {state.candidate_role} ({state.candidate_seniority}) in {state.candidate_industry}")

    await ctx.connect(auto_subscribe="audio_only")
    log.info("‚úÖ Connected to room: %s", room_name)

    # Configure STT with explicit language hint for better accuracy
    # Language hint helps the model expect certain language patterns
    stt_language = "zh" if spoken_language == "zh-TW" else "en"
    stt = openai.STT(
        model=STT_MODEL,
        language=stt_language,  # Explicit language hint
    )
    log.info(f"üé§ STT configured with language hint: {stt_language}")
    
    llm_instance = openai.LLM(model=LLM_MODEL)
    
    # Select TTS voice based on language
    if spoken_language == "zh-TW":
        tts = openai.TTS(voice=TTS_VOICE_ZH_TW)
        log.info(f"üîä Using TTS voice: {TTS_VOICE_ZH_TW} (Chinese)")
    else:
        tts = openai.TTS(voice=TTS_VOICE_EN)
        log.info(f"üîä Using TTS voice: {TTS_VOICE_EN} (English)")

    # Configure VAD with tuned settings for better sentence detection
    # - min_speech_duration: wait longer before considering speech started
    # - min_silence_duration: wait longer pause before ending utterance
    # - padding_duration: include more audio before/after speech
    vad = silero.VAD.load(
        min_speech_duration=0.25,    # Require 250ms of speech to start (default: 0.1)
        min_silence_duration=0.8,    # Wait 800ms of silence before ending (default: 0.3)
        padding_duration=0.3,        # Include 300ms padding (default: 0.1)
        activation_threshold=0.5,    # Confidence threshold (default: 0.5)
    )
    log.info("üîá VAD configured: min_silence=0.8s, min_speech=0.25s")

    session = AgentSession(
        stt=stt,
        llm=llm_instance,
        tts=tts,
        vad=vad,
    )

    with suppress(Exception):
        if hasattr(session, "set_barge_in"):
            session.set_barge_in(True)

    # Track for greeting tasks
    greeting_tasks = []
    
    # Track for repair turns
    pending_repair = {"needed": False}

    # Subscribe to conversation items
    @session.on("conversation_item_added")
    def on_conversation_item(event: ConversationItemAddedEvent):
        """Capture both user and agent messages with state tracking and repair detection"""
        try:
            role = event.item.role
            text = event.item.text_content
            
            if role == "user":
                state.user_responded = True
                state.last_activity_time = time.time()
                state.silence_retries = 0
                
                # Cancel pending greeting tasks
                for task in greeting_tasks:
                    if not task.done():
                        task.cancel()
                
                # Check STT quality
                if is_garbled_text(text) or not should_process(text):
                    state.consecutive_stt_failures += 1
                    log.warning(f"‚ö†Ô∏è Poor STT quality detected: '{text}' (failures: {state.consecutive_stt_failures})")
                    
                    # Trigger repair turn if needed
                    if needs_repair_turn(text, state.consecutive_stt_failures):
                        pending_repair["needed"] = True
                        state.total_repair_turns += 1
                        log.info(f"üîÑ Repair turn needed (total: {state.total_repair_turns})")
                else:
                    # Good transcription - reset failure counter
                    state.consecutive_stt_failures = 0
                    state.last_user_text = text
                    
                    # Detect topic from user's response
                    topic = detect_topic_from_text(text)
                    if topic:
                        state.mark_topic_covered(topic)
                        log.info(f"üìå Topic detected and marked: {topic}")
            
            elif role == "assistant":
                # Track praise usage
                praise_count = count_praise_in_text(text, state.spoken_language)
                if praise_count > 0:
                    state.praise_count += praise_count
                    log.warning(f"‚ö†Ô∏è Praise detected ({praise_count}): {text[:50]}")
                
                # Track if this looks like a question (ends with ?)
                if "?" in text or "Ôºü" in text:
                    state.question_count += 1
                    state.questions_asked.append(text[:100])
                    log.info(f"‚ùì Question #{state.question_count} asked")
            
            if text and should_process(text):
                enqueue_transcript(session_id, role, text)
                log.info(f"{'üë§' if role == 'user' else 'ü§ñ'} {role.capitalize()}: {text[:100]}")
                
        except Exception as e:
            log.error(f"Error in conversation_item handler: {e}")

    log.info("‚úÖ Subscribed to conversation events")

    # Start transcript flushing
    asyncio.create_task(_flush_transcripts())

    rio = build_room_input_options()
    agent = InterviewCoach(state)
    
    if rio:
        await session.start(room=ctx.room, agent=agent, room_input_options=rio)
    else:
        await session.start(room=ctx.room, agent=agent)

    log.info(f"üé§ {interview_type.title()} interview started in {spoken_language}")

    # Send greeting
    async def send_greeting():
        await asyncio.sleep(2)
        
        greeting = GREETINGS[interview_type].get(spoken_language, GREETINGS[interview_type]["zh-TW"])
        
        with suppress(Exception):
            if hasattr(session, "say"):
                await session.say(greeting, allow_interruptions=True)
        log.info(f"ü§ñ Sent {interview_type} greeting in {spoken_language}")
        state.current_stage = "questions"
        
        # Wait for response
        await asyncio.sleep(10)
        
        # Mic tip if no response
        if not state.user_responded:
            mic_tip = MIC_TIPS.get(spoken_language, MIC_TIPS["zh-TW"])
            with suppress(Exception):
                if hasattr(session, "say"):
                    await session.say(mic_tip, allow_interruptions=True)
            log.info(f"üîî Sent mic permission nudge")

    if not LISTEN_FIRST:
        task = asyncio.create_task(send_greeting())
        greeting_tasks.append(task)

    # ---------- NEVER GIVE UP WATCHDOG + REPAIR TURNS ----------
    async def watchdog():
        """Ensure interview never ends abruptly and handle repair turns"""
        while True:
            await asyncio.sleep(3)  # Check more frequently for repair turns
            
            # Handle pending repair turns
            if pending_repair["needed"] and state.total_repair_turns <= 3:
                pending_repair["needed"] = False
                repair_idx = min(state.total_repair_turns - 1, len(REPAIR_MESSAGES[spoken_language]) - 1)
                repair_msg = REPAIR_MESSAGES[spoken_language][repair_idx]
                with suppress(Exception):
                    if hasattr(session, "say"):
                        await session.say(repair_msg, allow_interruptions=True)
                log.info(f"üîÑ Sent repair turn: {repair_msg}")
                state.last_activity_time = time.time()
                continue
            
            current_time = time.time()
            silence_duration = current_time - state.last_activity_time
            
            # Check for prolonged silence
            if silence_duration > SILENCE_TIMEOUT_S and state.user_responded:
                if state.silence_retries < MAX_SILENCE_RETRIES:
                    state.silence_retries += 1
                    silence_msg = SILENCE_PROMPTS[spoken_language][state.silence_retries - 1]
                    with suppress(Exception):
                        if hasattr(session, "say"):
                            await session.say(silence_msg, allow_interruptions=True)
                    log.info(f"üîî Silence prompt #{state.silence_retries}")
                    state.last_activity_time = current_time
            
            # Check if we should wrap up
            if state.should_wrap_up() and state.current_stage == "questions":
                state.current_stage = "wrap_up"
                wrap_up_msg = WRAP_UP_PROMPTS[spoken_language]
                with suppress(Exception):
                    if hasattr(session, "say"):
                        await session.say(wrap_up_msg, allow_interruptions=True)
                log.info("üèÅ Starting wrap-up phase")

    asyncio.create_task(watchdog())

    # ---------- SESSION LIFETIME ----------
    try:
        await asyncio.sleep(SESSION_LIFETIME_S)
    except asyncio.CancelledError:
        pass

    # Always send final closing
    if state.current_stage != "ended":
        state.current_stage = "ended"
        final_msg = FINAL_CLOSING[spoken_language]
        with suppress(Exception):
            if hasattr(session, "say"):
                await session.say(final_msg, allow_interruptions=False)
        log.info("üèÅ Sent final closing message")

    log.info(f"üèÅ Interview ended | Questions: {state.question_count} | Praise count: {state.praise_count}")


if __name__ == "__main__":
    _load_env()
    setup_logging()
    cli.run_app(
        WorkerOptions(
            entrypoint_fnc=entrypoint,
            agent_name="LyraAI",
        )
    )