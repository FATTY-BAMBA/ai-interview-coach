import asyncio
import logging
import os
import pathlib
import re
import uuid
import time
import json
from collections import deque
from contextlib import suppress
from typing import Optional, List, Set, Dict
from dataclasses import dataclass, field

import httpx
from dotenv import load_dotenv, find_dotenv

from livekit.agents import (
    AgentSession,
    Agent,
    JobContext,
    WorkerOptions,
    cli,
    ConversationItemAddedEvent,
)
from livekit.plugins import openai, silero


# ---------- ENV LOADING ----------
def _load_env():
    here = pathlib.Path(__file__).resolve()
    root = here.parent.parent
    tried = [root / ".env.local", root / ".env", pathlib.Path(find_dotenv(usecwd=True) or "")]
    loaded = False
    for p in tried:
        if p and p.exists():
            load_dotenv(p, override=False)
            logging.getLogger(__name__).info("Loaded env file: %s", p)
            loaded = True
    if not loaded:
        logging.getLogger(__name__).info("No local env files found.")


# ---------- CONFIG ----------
LISTEN_FIRST = os.getenv("LISTEN_FIRST", "false").lower() == "true"

LLM_MODEL = os.getenv("LLM_MODEL", "gpt-4o")
STT_MODEL = os.getenv("STT_MODEL", "gpt-4o-transcribe")

TTS_VOICE_EN = os.getenv("TTS_VOICE_EN", "alloy")
TTS_VOICE_ZH_TW = os.getenv("TTS_VOICE_ZH_TW", "nova")

MIN_TRANSCRIPT_CHARS = int(os.getenv("MIN_TRANSCRIPT_CHARS", "2"))
SESSION_LIFETIME_S = int(os.getenv("SESSION_LIFETIME_S", "3600"))

API_URL = os.getenv("NEXT_PUBLIC_APP_URL", "http://localhost:3000")
API_TOKEN = os.getenv("API_TOKEN")

# Interview settings
MIN_QUESTIONS = 4
MAX_QUESTIONS = 6
SILENCE_TIMEOUT_S = 30
MAX_SILENCE_RETRIES = 3


# ---------- INTERVIEW STATE MACHINE ----------
@dataclass
class InterviewState:
    """Track interview progress to prevent repetition and ensure completion"""
    session_id: str
    interview_type: str
    spoken_language: str
    
    # State tracking
    current_stage: str = "intro"  # intro -> questions -> wrap_up -> ended
    questions_asked: List[str] = field(default_factory=list)
    topics_covered: Set[str] = field(default_factory=set)
    question_count: int = 0
    
    # Quality tracking
    praise_count: int = 0
    last_activity_time: float = field(default_factory=time.time)
    silence_retries: int = 0
    user_responded: bool = False
    
    # Competencies to cover (behavioral)
    available_topics: List[str] = field(default_factory=lambda: [
        "teamwork", "conflict", "leadership", "pressure", 
        "failure", "achievement", "communication", "problem_solving",
        "time_management", "adaptability"
    ])
    
    def mark_topic_covered(self, topic: str):
        self.topics_covered.add(topic)
        if topic in self.available_topics:
            self.available_topics.remove(topic)
    
    def get_remaining_topics(self) -> List[str]:
        return [t for t in self.available_topics if t not in self.topics_covered]
    
    def should_wrap_up(self) -> bool:
        return self.question_count >= MIN_QUESTIONS
    
    def must_end(self) -> bool:
        return self.question_count >= MAX_QUESTIONS
    
    def to_context_string(self) -> str:
        """Generate context string to pass to LLM"""
        return f"""
ã€ç•¶å‰é¢è©¦ç‹€æ…‹ã€‘
- éšŽæ®µ: {self.current_stage}
- å·²å•å•é¡Œæ•¸: {self.question_count}/{MIN_QUESTIONS}-{MAX_QUESTIONS}
- å·²æ¶µè“‹ä¸»é¡Œ: {', '.join(self.topics_covered) if self.topics_covered else 'ç„¡'}
- å‰©é¤˜å¯ç”¨ä¸»é¡Œ: {', '.join(self.get_remaining_topics()[:3])}
- å·²å•éŽçš„å•é¡Œ: {json.dumps(self.questions_asked[-3:], ensure_ascii=False) if self.questions_asked else 'ç„¡'}

ã€é‡è¦æé†’ã€‘
- ä¸è¦é‡è¤‡å·²å•éŽçš„å•é¡Œ
- é¸æ“‡å‰©é¤˜ä¸»é¡Œä¸­çš„ä¸€å€‹ä¾†æå•
- æ¯æ¬¡åªå•ä¸€å€‹å•é¡Œ
"""


# ---------- FORBIDDEN PHRASES (Anti-praise) ----------
FORBIDDEN_PRAISE_ZH = [
    "å¤ªæ£’äº†", "éžå¸¸æ£’", "å¤ªå¥½äº†", "éžå¸¸å¥½", "å®Œç¾Ž", "å¤ªå®Œç¾Ž",
    "éžå¸¸å„ªç§€", "å¤ªå„ªç§€", "å¤ªåŽ²å®³", "éžå¸¸åŽ²å®³", "å¾ˆæ£’", "çœŸæ£’",
    "excellent", "perfect", "amazing", "wonderful", "fantastic",
    "å¤ªè®šäº†", "éžå¸¸è®š", "è¶…ç´šæ£’", "è¶…æ£’", "è¶…åŽ²å®³"
]

FORBIDDEN_PRAISE_EN = [
    "excellent", "perfect", "amazing", "wonderful", "fantastic",
    "brilliant", "outstanding", "exceptional", "superb", "incredible",
    "that's great", "that's perfect", "that's amazing"
]

ALLOWED_ACKNOWLEDGMENTS_ZH = [
    "å¥½çš„", "å—¯", "äº†è§£", "è¬è¬åˆ†äº«", "å¥½", "æˆ‘æ˜Žç™½äº†"
]

ALLOWED_ACKNOWLEDGMENTS_EN = [
    "okay", "I see", "got it", "thanks for sharing", "understood"
]


# ---------- QUESTION TEMPLATES BY TOPIC ----------
QUESTION_TEMPLATES = {
    "behavioral": {
        "teamwork": {
            "zh-TW": [
                "è«‹åˆ†äº«ä¸€å€‹ä½ èˆ‡åœ˜éšŠåˆä½œå®Œæˆå›°é›£ä»»å‹™çš„ç¶“é©—ã€‚",
                "è«‡è«‡ä¸€æ¬¡ä½ åœ¨åœ˜éšŠä¸­æ‰®æ¼”é‡è¦è§’è‰²çš„ç¶“æ­·ã€‚",
            ],
            "en-US": [
                "Share an experience where you collaborated with a team on a difficult task.",
                "Tell me about a time you played a key role in your team.",
            ]
        },
        "conflict": {
            "zh-TW": [
                "æè¿°ä¸€æ¬¡ä½ èˆ‡åŒäº‹æ„è¦‹ä¸åˆçš„æƒ…æ³ï¼Œä½ å¦‚ä½•è™•ç†ï¼Ÿ",
                "è«‡è«‡ä¸€æ¬¡ä½ éœ€è¦è™•ç†åœ˜éšŠè¡çªçš„ç¶“é©—ã€‚",
            ],
            "en-US": [
                "Describe a situation where you disagreed with a colleague. How did you handle it?",
                "Tell me about a time you had to resolve a team conflict.",
            ]
        },
        "leadership": {
            "zh-TW": [
                "åˆ†äº«ä¸€æ¬¡ä½ å¸¶é ˜åœ˜éšŠæˆ–å°ˆæ¡ˆçš„ç¶“é©—ã€‚",
                "è«‡è«‡ä½ å¦‚ä½•å½±éŸ¿æˆ–èªªæœä»–äººæŽ¥å—ä½ çš„æƒ³æ³•ã€‚",
            ],
            "en-US": [
                "Share an experience leading a team or project.",
                "Tell me how you influenced or persuaded others to accept your idea.",
            ]
        },
        "pressure": {
            "zh-TW": [
                "æè¿°ä¸€æ¬¡ä½ åœ¨å£“åŠ›ä¸‹å·¥ä½œçš„ç¶“é©—ï¼Œä½ å¦‚ä½•æ‡‰å°ï¼Ÿ",
                "è«‡è«‡ä¸€å€‹deadlineå¾ˆç·Šçš„å°ˆæ¡ˆï¼Œä½ æ€Žéº¼è™•ç†çš„ï¼Ÿ",
            ],
            "en-US": [
                "Describe a time you worked under pressure. How did you cope?",
                "Tell me about a project with a tight deadline. How did you handle it?",
            ]
        },
        "failure": {
            "zh-TW": [
                "åˆ†äº«ä¸€æ¬¡å·¥ä½œä¸Šçš„å¤±æ•—ç¶“é©—ï¼Œä½ å¾žä¸­å­¸åˆ°ä»€éº¼ï¼Ÿ",
                "è«‡è«‡ä¸€å€‹æ²’æœ‰é”åˆ°é æœŸçµæžœçš„å°ˆæ¡ˆã€‚",
            ],
            "en-US": [
                "Share a work failure and what you learned from it.",
                "Tell me about a project that didn't meet expectations.",
            ]
        },
        "achievement": {
            "zh-TW": [
                "è«‡è«‡ä½ æœ€è‡ªè±ªçš„ä¸€å€‹å·¥ä½œæˆå°±ã€‚",
                "åˆ†äº«ä¸€å€‹ä½ è¶…è¶Šé æœŸå®Œæˆä»»å‹™çš„ç¶“é©—ã€‚",
            ],
            "en-US": [
                "Tell me about your proudest work achievement.",
                "Share an experience where you exceeded expectations.",
            ]
        },
        "problem_solving": {
            "zh-TW": [
                "æè¿°ä¸€å€‹ä½ è§£æ±ºè¤‡é›œå•é¡Œçš„ç¶“é©—ã€‚",
                "è«‡è«‡ä½ å¦‚ä½•è™•ç†ä¸€å€‹çœ‹ä¼¼ç„¡è§£çš„æŒ‘æˆ°ã€‚",
            ],
            "en-US": [
                "Describe your experience solving a complex problem.",
                "Tell me how you handled a seemingly unsolvable challenge.",
            ]
        },
        "communication": {
            "zh-TW": [
                "åˆ†äº«ä¸€æ¬¡ä½ éœ€è¦å‘éžå°ˆæ¥­äººå£«è§£é‡‹è¤‡é›œæ¦‚å¿µçš„ç¶“é©—ã€‚",
                "è«‡è«‡ä½ å¦‚ä½•è™•ç†æºé€šä¸è‰¯çš„æƒ…æ³ã€‚",
            ],
            "en-US": [
                "Share a time you explained a complex concept to non-experts.",
                "Tell me how you handled a miscommunication situation.",
            ]
        },
    }
}

# STAR Follow-up templates
FOLLOWUP_TEMPLATES = {
    "zh-TW": [
        "ç•¶æ™‚çš„æƒ…å¢ƒæ˜¯ä»€éº¼ï¼Ÿå¯ä»¥æ›´å…·é«”æè¿°å—Žï¼Ÿ",
        "ä½ å…·é«”åšäº†ä»€éº¼è¡Œå‹•ï¼Ÿ",
        "çµæžœå¦‚ä½•ï¼Ÿæœ‰æ²’æœ‰æ•¸å­—å¯ä»¥é‡åŒ–ï¼Ÿ",
        "å¦‚æžœé‡ä¾†ä¸€æ¬¡ï¼Œä½ æœƒæœ‰ä»€éº¼ä¸åŒçš„åšæ³•ï¼Ÿ",
        "é€™å€‹ç¶“é©—å°ä½ å¾Œä¾†çš„å·¥ä½œæœ‰ä»€éº¼å½±éŸ¿ï¼Ÿ",
        "ä½ å¾žé€™å€‹ç¶“é©—ä¸­å­¸åˆ°ä»€éº¼ï¼Ÿ",
    ],
    "en-US": [
        "What was the specific situation? Can you describe it more?",
        "What specific actions did you take?",
        "What was the result? Any numbers to quantify it?",
        "If you could do it again, what would you do differently?",
        "How did this experience affect your later work?",
        "What did you learn from this experience?",
    ]
}


# ---------- LANGUAGE-LOCKED INTERVIEWER PROMPT ----------
def get_interviewer_prompt(state: InterviewState) -> str:
    """Generate interviewer-only prompt (NO teaching, NO coaching)"""
    
    lang = state.spoken_language
    interview_type = state.interview_type
    
    if lang == "zh-TW":
        return f"""ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„é¢è©¦å®˜ï¼Œæ­£åœ¨é€²è¡Œ{interview_type}é¢è©¦ã€‚

ðŸ”’ã€èªžè¨€è¦å‰‡ - çµ•å°ä¸å¯é•åã€‘
- å…¨ç¨‹åªèƒ½ä½¿ç”¨ç¹é«”ä¸­æ–‡ï¼ˆå°ç£ç”¨èªžï¼‰
- çµ•å°ä¸å¯ä»¥åˆ‡æ›åˆ°è‹±æ–‡æˆ–å…¶ä»–èªžè¨€
- å¦‚æžœæ±‚è·è€…ç”¨è‹±æ–‡å•è©±ï¼Œç”¨ä¸­æ–‡å›žç­”ï¼šã€Œè®“æˆ‘å€‘ç¹¼çºŒç”¨ä¸­æ–‡é€²è¡Œé¢è©¦ã€‚ã€
- èªžè¨€éŽ–å®šï¼Œç„¡ä¾‹å¤–

ðŸŽ­ã€ä½ çš„è§’è‰² - é¢è©¦å®˜ï¼Œä¸æ˜¯è€å¸«ã€‘
ä½ æ˜¯é¢è©¦å®˜ï¼Œä¸æ˜¯å°Žå¸«ã€æ•™ç·´æˆ–è€å¸«ã€‚
- âœ… ä½ çš„å·¥ä½œï¼šæå•ã€è†è½ã€è¿½å•
- âŒ ä¸æ˜¯ä½ çš„å·¥ä½œï¼šæ•™å­¸ã€è§£é‡‹ç†æƒ³ç­”æ¡ˆã€çµ¦å»ºè­°

ðŸš«ã€çµ•å°ç¦æ­¢çš„è¡Œç‚ºã€‘
1. ä¸è¦æ•™æ±‚è·è€…æ€Žéº¼å›žç­”
2. ä¸è¦è§£é‡‹ã€Œæ¯”è¼ƒå¥½çš„ç­”æ¡ˆæ˜¯...ã€
3. ä¸è¦çµ¦å¤ªå¤šè®šç¾Žï¼ˆæœ€å¤šèªªã€Œå¥½çš„ã€ã€Œäº†è§£ã€ï¼‰
4. ä¸è¦èªªã€Œå¤ªæ£’äº†ã€ã€Œéžå¸¸å¥½ã€ã€Œå®Œç¾Žã€ç­‰èª‡å¼µè®šç¾Ž
5. ä¸è¦ä¸€æ¬¡å•å¤šå€‹å•é¡Œ
6. ä¸è¦é‡è¤‡å·²ç¶“å•éŽçš„å•é¡Œ
7. ä¸è¦é•·ç¯‡å¤§è«–ï¼Œä¿æŒç°¡çŸ­

ðŸ“‹ã€å›žæ‡‰æ ¼å¼ - å¿…é ˆéµå®ˆã€‘
æ¯æ¬¡å›žæ‡‰å¿…é ˆï¼š
1. ç°¡çŸ­å›žæ‡‰ï¼ˆæœ€å¤š1-2å¥ï¼Œå¦‚ã€Œå¥½çš„ï¼Œäº†è§£ã€‚ã€ï¼‰
2. ä»¥ä¸€å€‹æ–°å•é¡Œçµå°¾

ç¯„ä¾‹å¥½çš„å›žæ‡‰ï¼š
ã€Œäº†è§£ã€‚é‚£è«‹å•ä½ åœ¨é‚£å€‹å°ˆæ¡ˆä¸­ï¼Œå…·é«”è² è²¬å“ªäº›éƒ¨åˆ†ï¼Ÿã€
ã€Œå¥½çš„ã€‚å¯ä»¥åˆ†äº«ä¸€ä¸‹ç•¶æ™‚çš„çµæžœå—Žï¼Ÿæœ‰æ²’æœ‰å…·é«”æ•¸å­—ï¼Ÿã€

ç¯„ä¾‹ä¸å¥½çš„å›žæ‡‰ï¼š
ã€Œå¤ªæ£’äº†ï¼ä½ çš„å›žç­”éžå¸¸å¥½ï¼é€™ç¨®ç¶“é©—å¾ˆé‡è¦ï¼Œå› ç‚º...ï¼ˆé•·ç¯‡è§£é‡‹ï¼‰ã€

ðŸ—£ï¸ã€èªªè©±é¢¨æ ¼ã€‘
- ç”¨å£èªžåŒ–çš„å°ç£åœ‹èªž
- çŸ­å¥å­ï¼ŒåƒçœŸäººå°è©±
- ä¸è¦ç”¨æ›¸é¢èªžæˆ–æ–‡è¨€æ–‡
- åƒåœ¨å’–å•¡å»³é¢è©¦ä¸€æ¨£è‡ªç„¶

â°ã€é¢è©¦æµç¨‹ã€‘
1. å• {MIN_QUESTIONS}-{MAX_QUESTIONS} å€‹ä¸»è¦å•é¡Œ
2. æ¯å€‹å•é¡Œå¯ä»¥è¿½å• 1-2 å€‹follow-up
3. ä¸è¦æå‰çµæŸ
4. æ™‚é–“åˆ°äº†æ‰åšç¸½çµ

{state.to_context_string()}

è¨˜ä½ï¼šä½ æ˜¯é¢è©¦å®˜ï¼Œåªè² è²¬æå•ã€‚æ‰€æœ‰æ•™å­¸å’Œå»ºè­°éƒ½ç•™åˆ°é¢è©¦çµæŸå¾Œçš„è©•ä¼°å ±å‘Šã€‚
"""
    
    else:  # en-US
        return f"""You are a professional interviewer conducting a {interview_type} interview.

ðŸ”’ã€LANGUAGE RULES - ABSOLUTEã€‘
- Speak ONLY in English throughout
- NEVER switch to another language
- If candidate speaks another language, respond: "Let's continue in English."
- Language is LOCKED, no exceptions

ðŸŽ­ã€YOUR ROLE - Interviewer, NOT Teacherã€‘
You are an interviewer, NOT a tutor, coach, or teacher.
- âœ… Your job: Ask questions, listen, probe deeper
- âŒ NOT your job: Teach, explain ideal answers, give advice

ðŸš«ã€FORBIDDEN BEHAVIORSã€‘
1. Do NOT teach how to answer
2. Do NOT explain "a better answer would be..."
3. Do NOT over-praise (max: "okay" "I see" "got it")
4. Do NOT say "excellent" "perfect" "amazing" etc.
5. Do NOT ask multiple questions at once
6. Do NOT repeat questions already asked
7. Do NOT give long responses, keep it brief

ðŸ“‹ã€RESPONSE FORMAT - REQUIREDã€‘
Every response must:
1. Brief acknowledgment (1-2 sentences max, e.g., "Got it.")
2. End with ONE new question

Good example:
"I see. What specific actions did you take in that situation?"

Bad example:
"That's amazing! What a great experience! This is important because... (long explanation)"

ðŸ—£ï¸ã€SPEAKING STYLEã€‘
- Conversational, natural English
- Short sentences, like real conversation
- Not formal or academic
- Like interviewing at a coffee shop

â°ã€INTERVIEW FLOWã€‘
1. Ask {MIN_QUESTIONS}-{MAX_QUESTIONS} main questions
2. 1-2 follow-ups per question allowed
3. Do NOT end early
4. Only wrap up when time is up

{state.to_context_string()}

Remember: You are the interviewer. Only ask questions. All teaching and advice is for the evaluation report AFTER the interview.
"""


# ---------- WRAP-UP PROMPTS ----------
WRAP_UP_PROMPTS = {
    "zh-TW": """å¥½çš„ï¼Œæˆ‘å€‘çš„é¢è©¦æ™‚é–“å·®ä¸å¤šäº†ã€‚æ„Ÿè¬ä½ ä»Šå¤©çš„åˆ†äº«ï¼Œä½ çš„å›žç­”è®“æˆ‘å°ä½ æœ‰æ›´å¤šäº†è§£ã€‚æˆ‘å€‘æœƒåœ¨é¢è©¦çµæŸå¾Œæä¾›è©³ç´°çš„è©•ä¼°å ±å‘Šçµ¦ä½ ã€‚é‚„æœ‰ä»€éº¼å•é¡Œæƒ³å•æˆ‘å—Žï¼Ÿ""",
    
    "en-US": """Alright, we're almost out of time. Thank you for sharing today - your answers helped me understand you better. We'll provide a detailed evaluation report after the interview. Do you have any questions for me?"""
}

FINAL_CLOSING = {
    "zh-TW": """å¥½çš„ï¼Œé‚£ä»Šå¤©çš„é¢è©¦å°±åˆ°é€™è£¡ã€‚è¬è¬ä½ çš„æ™‚é–“ï¼Œç¥ä½ æŽ¥ä¸‹ä¾†ä¸€åˆ‡é †åˆ©ï¼""",
    "en-US": """Okay, that concludes our interview today. Thank you for your time, and best of luck with everything!"""
}

# Never give up messages
SILENCE_PROMPTS = {
    "zh-TW": [
        "ä¸å¥½æ„æ€ï¼Œæˆ‘é€™é‚Šå¥½åƒæ²’æœ‰æ”¶åˆ°ä½ çš„è²éŸ³ï¼Œå¯ä»¥å†èªªä¸€æ¬¡å—Žï¼Ÿ",
        "æŠ±æ­‰ï¼Œå‰›å‰›å¯èƒ½æœ‰é»žæŠ€è¡“å•é¡Œã€‚ä½ å¯ä»¥å†é‡è¤‡ä¸€æ¬¡å—Žï¼Ÿ",
        "æˆ‘è½ä¸å¤ªæ¸…æ¥šï¼Œå¯ä»¥è«‹ä½ é è¿‘éº¥å…‹é¢¨å†èªªä¸€æ¬¡å—Žï¼Ÿ",
    ],
    "en-US": [
        "Sorry, I didn't catch that. Could you repeat it?",
        "Apologies, there might have been a technical issue. Could you say that again?",
        "I couldn't hear clearly. Could you move closer to the mic and repeat?",
    ]
}


# ---------- GREETINGS ----------
GREETINGS = {
    "behavioral": {
        "zh-TW": "å—¨ï¼æˆ‘æ˜¯ä»Šå¤©çš„é¢è©¦å®˜ã€‚é€™æ˜¯ä¸€å ´è¡Œç‚ºé¢è©¦ï¼Œæˆ‘æœƒå•ä½ ä¸€äº›é—œæ–¼éŽåŽ»å·¥ä½œç¶“é©—çš„å•é¡Œã€‚æº–å‚™å¥½çš„è©±ï¼Œè«‹å…ˆç°¡å–®è‡ªæˆ‘ä»‹ç´¹ä¸€ä¸‹ã€‚",
        "en-US": "Hi! I'm your interviewer today. This is a behavioral interview where I'll ask about your past work experiences. When you're ready, please briefly introduce yourself.",
    },
    "technical": {
        "zh-TW": "å—¨ï¼æˆ‘æ˜¯ä»Šå¤©çš„æŠ€è¡“é¢è©¦å®˜ã€‚æˆ‘æœƒå•ä¸€äº›ç¨‹å¼å’ŒæŠ€è¡“ç›¸é—œçš„å•é¡Œã€‚è«‹å…ˆç°¡å–®ä»‹ç´¹ä½ çš„æŠ€è¡“èƒŒæ™¯ã€‚",
        "en-US": "Hi! I'm your technical interviewer today. I'll ask some coding and technical questions. Please briefly introduce your technical background.",
    },
    "system-design": {
        "zh-TW": "å—¨ï¼æˆ‘æ˜¯ä»Šå¤©çš„ç³»çµ±è¨­è¨ˆé¢è©¦å®˜ã€‚æˆ‘å€‘æœƒè¨Žè«–ä¸€äº›æž¶æ§‹è¨­è¨ˆçš„å•é¡Œã€‚è«‹å…ˆåˆ†äº«ä¸€ä¸‹ä½ çš„ç³»çµ±è¨­è¨ˆç¶“é©—ã€‚",
        "en-US": "Hi! I'm your system design interviewer today. We'll discuss some architecture questions. Please share your system design experience.",
    },
    "case-study": {
        "zh-TW": "å—¨ï¼æˆ‘æ˜¯ä»Šå¤©çš„æ¡ˆä¾‹é¢è©¦å®˜ã€‚æˆ‘æœƒæå‡ºä¸€äº›å•†æ¥­å•é¡Œè®“ä½ åˆ†æžã€‚è«‹å…ˆç°¡å–®ä»‹ç´¹ä½ çš„åˆ†æžç¶“é©—ã€‚",
        "en-US": "Hi! I'm your case study interviewer today. I'll present some business problems for analysis. Please briefly introduce your analytical experience.",
    },
}

MIC_TIPS = {
    "zh-TW": "æˆ‘é‚„æ²’æ”¶åˆ°éº¥å…‹é¢¨çš„è²éŸ³ï¼Œè«‹ç¢ºèªç€è¦½å™¨å·²æŽˆæ¬Šéº¥å…‹é¢¨æ¬Šé™ã€‚",
    "en-US": "I'm not receiving microphone audio. Please check that your browser has microphone permissions enabled.",
}


# ---------- LOGGING ----------
def setup_logging():
    level = os.getenv("LOG_LEVEL", "INFO").upper()
    logging.basicConfig(
        level=level,
        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
    )
    log = logging.getLogger("agent")
    log.info("Starting LyraAI Interview Coach v2 | pid=%s", os.getpid())
    return log


# ---------- AGENT ----------
class InterviewCoach(Agent):
    def __init__(self, state: InterviewState):
        system_prompt = get_interviewer_prompt(state)
        super().__init__(instructions=system_prompt)
        self.state = state


# ---------- HELPERS ----------
def build_room_input_options() -> Optional[object]:
    try:
        from livekit.agents import RoomInputOptions
        with suppress(TypeError):
            return RoomInputOptions(audio=True, video=False, screen=False, close_on_disconnect=False)
        with suppress(TypeError):
            return RoomInputOptions(microphone=True, camera=False, screen=False, close_on_disconnect=False)
        return None
    except Exception:
        return None

def should_process(text: str) -> bool:
    return bool(text and len(text.strip()) >= MIN_TRANSCRIPT_CHARS)

def detect_topic_from_text(text: str) -> Optional[str]:
    """Detect which topic the conversation is about"""
    topic_keywords = {
        "teamwork": ["åœ˜éšŠ", "åˆä½œ", "team", "collaborate", "together"],
        "conflict": ["è¡çª", "æ„è¦‹ä¸åˆ", "çˆ­åŸ·", "conflict", "disagree"],
        "leadership": ["é ˜å°Ž", "å¸¶é ˜", "lead", "leadership", "manage"],
        "pressure": ["å£“åŠ›", "deadline", "è¶•", "pressure", "stress"],
        "failure": ["å¤±æ•—", "éŒ¯èª¤", "fail", "mistake", "wrong"],
        "achievement": ["æˆå°±", "æˆåŠŸ", "è‡ªè±ª", "achieve", "proud", "success"],
        "problem_solving": ["è§£æ±º", "å•é¡Œ", "solve", "problem", "challenge"],
        "communication": ["æºé€š", "è¡¨é”", "communicate", "explain"],
    }
    
    text_lower = text.lower()
    for topic, keywords in topic_keywords.items():
        if any(kw in text_lower for kw in keywords):
            return topic
    return None

def count_praise_in_text(text: str, lang: str) -> int:
    """Count forbidden praise phrases in text"""
    forbidden = FORBIDDEN_PRAISE_ZH if lang == "zh-TW" else FORBIDDEN_PRAISE_EN
    count = 0
    text_lower = text.lower()
    for phrase in forbidden:
        if phrase.lower() in text_lower:
            count += 1
    return count


# ---------- TRANSCRIPT QUEUE ----------
_transcript_q = deque(maxlen=1000)

def enqueue_transcript(session_id: str, role: str, text: str):
    _transcript_q.append({"sessionId": session_id, "role": role, "text": text})
    logging.getLogger("agent").info(f"ðŸ’¬ Queued {role}: {text[:80]}")

async def _flush_transcripts():
    async with httpx.AsyncClient(timeout=5.0) as client:
        while True:
            if _transcript_q:
                item = _transcript_q.popleft()
                for attempt in range(4):
                    try:
                        r = await client.post(
                            f"{API_URL}/api/interview/transcript",
                            json=item,
                            headers=({"Authorization": f"Bearer {API_TOKEN}"} if API_TOKEN else {}),
                        )
                        if r.status_code == 200:
                            logging.getLogger("agent").info(f"ðŸ’¾ Saved {item['role']}: {item['text'][:50]}")
                            break
                        elif r.status_code < 500:
                            break
                    except Exception as e:
                        logging.getLogger("agent").debug(f"Transcript save attempt {attempt + 1} failed: {e}")
                    await asyncio.sleep(0.3 * (2**attempt))
            else:
                await asyncio.sleep(0.05)


# ---------- FETCH SESSION BY ROOM NAME ----------
async def fetch_session_by_room(room_name: str) -> tuple[str, str, str]:
    """Fetch session ID, interview type, and spoken language from database"""
    log = logging.getLogger("agent")
    try:
        async with httpx.AsyncClient(timeout=5.0) as client:
            r = await client.get(
                f"{API_URL}/api/interview/by-room/{room_name}",
                headers=({"Authorization": f"Bearer {API_TOKEN}"} if API_TOKEN else {})
            )
            if r.status_code == 200:
                data = r.json()
                session = data.get("session", {})
                session_id = session.get("id")
                interview_type = session.get("interviewType", "behavioral")
                spoken_language = session.get("spokenLanguage", "zh-TW")
                log.info(f"âœ… Found session: {session_id}, type: {interview_type}, language: {spoken_language}")
                return session_id, interview_type, spoken_language
            else:
                log.warning(f"Session lookup failed: {r.status_code}")
    except Exception as e:
        log.warning(f"Failed to fetch session by room: {e}")
    
    return str(uuid.uuid4()), "behavioral", "zh-TW"


# ---------- ENTRYPOINT ----------
async def entrypoint(ctx: JobContext):
    log = logging.getLogger("agent")

    room_name = ctx.room.name or ""
    
    # Fetch session info
    session_id, interview_type, spoken_language = await fetch_session_by_room(room_name)
    
    # Initialize interview state
    state = InterviewState(
        session_id=session_id,
        interview_type=interview_type,
        spoken_language=spoken_language,
    )
    
    log.info(f"ðŸŒ Language locked to: {spoken_language}")
    log.info(f"ðŸ“‹ Interview type: {interview_type}")

    await ctx.connect(auto_subscribe="audio_only")
    log.info("âœ… Connected to room: %s", room_name)

    # Configure STT/LLM/TTS
    stt = openai.STT(model=STT_MODEL)
    llm_instance = openai.LLM(model=LLM_MODEL)
    
    # Select TTS voice based on language
    if spoken_language == "zh-TW":
        tts = openai.TTS(voice=TTS_VOICE_ZH_TW)
        log.info(f"ðŸ”Š Using TTS voice: {TTS_VOICE_ZH_TW} (Chinese)")
    else:
        tts = openai.TTS(voice=TTS_VOICE_EN)
        log.info(f"ðŸ”Š Using TTS voice: {TTS_VOICE_EN} (English)")

    session = AgentSession(
        stt=stt,
        llm=llm_instance,
        tts=tts,
        vad=silero.VAD.load(),
    )

    with suppress(Exception):
        if hasattr(session, "set_barge_in"):
            session.set_barge_in(True)

    # Track for greeting tasks
    greeting_tasks = []

    # Subscribe to conversation items
    @session.on("conversation_item_added")
    def on_conversation_item(event: ConversationItemAddedEvent):
        """Capture both user and agent messages with state tracking"""
        try:
            role = event.item.role
            text = event.item.text_content
            
            if role == "user":
                state.user_responded = True
                state.last_activity_time = time.time()
                state.silence_retries = 0
                
                # Cancel pending greeting tasks
                for task in greeting_tasks:
                    if not task.done():
                        task.cancel()
                
                # Detect topic from user's response
                topic = detect_topic_from_text(text)
                if topic:
                    state.mark_topic_covered(topic)
                    log.info(f"ðŸ“Œ Topic detected and marked: {topic}")
            
            elif role == "assistant":
                # Track praise usage
                praise_count = count_praise_in_text(text, state.spoken_language)
                if praise_count > 0:
                    state.praise_count += praise_count
                    log.warning(f"âš ï¸ Praise detected ({praise_count}): {text[:50]}")
                
                # Track if this looks like a question (ends with ?)
                if "?" in text or "ï¼Ÿ" in text:
                    state.question_count += 1
                    state.questions_asked.append(text[:100])
                    log.info(f"â“ Question #{state.question_count} asked")
            
            if text and should_process(text):
                enqueue_transcript(session_id, role, text)
                log.info(f"{'ðŸ‘¤' if role == 'user' else 'ðŸ¤–'} {role.capitalize()}: {text[:100]}")
                
        except Exception as e:
            log.error(f"Error in conversation_item handler: {e}")

    log.info("âœ… Subscribed to conversation events")

    # Start transcript flushing
    asyncio.create_task(_flush_transcripts())

    rio = build_room_input_options()
    agent = InterviewCoach(state)
    
    if rio:
        await session.start(room=ctx.room, agent=agent, room_input_options=rio)
    else:
        await session.start(room=ctx.room, agent=agent)

    log.info(f"ðŸŽ¤ {interview_type.title()} interview started in {spoken_language}")

    # Send greeting
    async def send_greeting():
        await asyncio.sleep(2)
        
        greeting = GREETINGS[interview_type].get(spoken_language, GREETINGS[interview_type]["zh-TW"])
        
        with suppress(Exception):
            if hasattr(session, "say"):
                await session.say(greeting, allow_interruptions=True)
        log.info(f"ðŸ¤– Sent {interview_type} greeting in {spoken_language}")
        state.current_stage = "questions"
        
        # Wait for response
        await asyncio.sleep(10)
        
        # Mic tip if no response
        if not state.user_responded:
            mic_tip = MIC_TIPS.get(spoken_language, MIC_TIPS["zh-TW"])
            with suppress(Exception):
                if hasattr(session, "say"):
                    await session.say(mic_tip, allow_interruptions=True)
            log.info(f"ðŸ”” Sent mic permission nudge")

    if not LISTEN_FIRST:
        task = asyncio.create_task(send_greeting())
        greeting_tasks.append(task)

    # ---------- NEVER GIVE UP WATCHDOG ----------
    async def watchdog():
        """Ensure interview never ends abruptly"""
        while True:
            await asyncio.sleep(10)
            
            current_time = time.time()
            silence_duration = current_time - state.last_activity_time
            
            # Check for prolonged silence
            if silence_duration > SILENCE_TIMEOUT_S and state.user_responded:
                if state.silence_retries < MAX_SILENCE_RETRIES:
                    state.silence_retries += 1
                    silence_msg = SILENCE_PROMPTS[spoken_language][state.silence_retries - 1]
                    with suppress(Exception):
                        if hasattr(session, "say"):
                            await session.say(silence_msg, allow_interruptions=True)
                    log.info(f"ðŸ”” Silence prompt #{state.silence_retries}")
                    state.last_activity_time = current_time
            
            # Check if we should wrap up
            if state.should_wrap_up() and state.current_stage == "questions":
                state.current_stage = "wrap_up"
                wrap_up_msg = WRAP_UP_PROMPTS[spoken_language]
                with suppress(Exception):
                    if hasattr(session, "say"):
                        await session.say(wrap_up_msg, allow_interruptions=True)
                log.info("ðŸ Starting wrap-up phase")

    asyncio.create_task(watchdog())

    # ---------- SESSION LIFETIME ----------
    try:
        await asyncio.sleep(SESSION_LIFETIME_S)
    except asyncio.CancelledError:
        pass

    # Always send final closing
    if state.current_stage != "ended":
        state.current_stage = "ended"
        final_msg = FINAL_CLOSING[spoken_language]
        with suppress(Exception):
            if hasattr(session, "say"):
                await session.say(final_msg, allow_interruptions=False)
        log.info("ðŸ Sent final closing message")

    log.info(f"ðŸ Interview ended | Questions: {state.question_count} | Praise count: {state.praise_count}")


if __name__ == "__main__":
    _load_env()
    setup_logging()
    cli.run_app(
        WorkerOptions(
            entrypoint_fnc=entrypoint,
            agent_name="LyraAI",
        )
    )